log_format  upstreamlog  '$remote_addr $remote_user [$time_local] '
                         '$request status:$status bytes:$body_bytes_sent '
                         'upstream:$upstream_addr';

# Resolver definition with custom cache
resolver 127.0.0.11 valid=30s ipv6=off;

# Shared dict for storing metrics (e.g., last 5-second average times)
lua_shared_dict metrics_store 10m;


# init_worker_by_lua_block to initialize the shared dict
init_worker_by_lua_block {
    local http = require "resty.http"
    local cjson = require "cjson"
    local metrics_dict = ngx.shared.metrics_store

    local function fetch_and_store_metrics(premature)
        if premature then
            return
        end

        local httpc = http.new()

        -- Collect the active_connections metric.
        local res, err = httpc:request_uri("http://prometheus:9090/api/v1/query", {
            method = "GET",
            query = {
               query = "avg_over_time(active_connections{instance=~\"api-server1:8080|api-server2:8080\", job=\"api-server\"}[3s])"
            },
            timeout = 2000
        })

        if not res or res.status ~= 200 then
            ngx.log(ngx.ERR, "Failed to fetch metrics from Prometheus: ", err) 
            return
        end

        -- Analyze JSON
        local data = cjson.decode(res.body)
        if not data or not data.data or not data.data.result then
            ngx.log(ngx.ERR, "Invalid data from Prometheus: ", res.body)
            return
        end

        -- Collect execution_time
        local res_time, err_time = httpc:request_uri("http://prometheus:9090/api/v1/query", {
            method = "GET",
            query = {
               query = "rate(execution_time_sum{instance=~\"api-server1:8080|api-server2:8080\", job=\"api-server\"}[3s]) / rate(execution_time_count{instance=~\"api-server1:8080|api-server2:8080\", job=\"api-server\"}[3s])"
            },
            timeout = 2000
        })
        if not res_time or res_time.status ~= 200 then
            ngx.log(ngx.ERR, "Failed to fetch metrics from Prometheus: ", err_time) 
            return
        end

        local data_time = cjson.decode(res_time.body)
        if not data_time or not data_time.data or not data_time.data.result then
            ngx.log(ngx.ERR, "Invalid data from Prometheus: ", res_time.body)
            return
        end

        for _, item in ipairs(data_time.data.result) do
            local instance = item.metric.instance
            local val_str = item.value and item.value[2]
            if instance and val_str then
                local val_num = tonumber(val_str)
                if val_num then
                    metrics_dict:set(instance .. ":execution_time", val_num)
                end
            end
        end

        ngx.log(ngx.INFO, "Number of returned metrics from Prometheus: ", data.data.result)

        -- 遍历返回结果，把每个 instance 的值存到共享字典
        for _, item in ipairs(data.data.result) do

            ngx.log(ngx.INFO, "Prom item: instance=", item.metric.instance, ", value=", item.value and item.value[2])
            
            local instance = item.metric.instance
            local val_str = item.value and item.value[2]

            if instance and val_str then
                local val_num = tonumber(val_str)
                if val_num then
                    metrics_dict:set(instance .. ":active_connections", val_num)
                    ngx.log(ngx.INFO, "Fetched active_connections for instance ", instance, " = ", val_num)
                end
            end
        end
    end


    -- 每 3 秒执行一次
    local ok, err = ngx.timer.every(3, fetch_and_store_metrics)
    if not ok then
        ngx.log(ngx.ERR, "failed to create timer: ", err)
    end
}


upstream factorization_servers {
    balancer_by_lua_block {
        local balancer = require("ngx.balancer")
        local metrics_dict = ngx.shared.metrics_store
        local epsilon = 0.001  -- 避免 exec_time 为 0 时的除零或零权重问题

        local function effective_load(instance)
            local active = metrics_dict:get(instance .. ":active_connections") or 0
            local exec = metrics_dict:get(instance .. ":execution_time") or 0
            return active * (exec + epsilon)
        end

        -- 后端列表使用 Prometheus 返回的 instance 名称
        local backends = {
            "api-server1:8080",
            "api-server2:8080"
        }

        local chosen_instance = nil
        local min_load = math.huge

        for _, instance in ipairs(backends) do
            local load = effective_load(instance)
            ngx.log(ngx.INFO, "Instance ", instance, " effective_load: ", load)
            if load < min_load then
                min_load = load
                chosen_instance = instance
            end
        end

        ngx.log(ngx.INFO, "Final chosen instance: ", chosen_instance, " with effective_load: ", min_load)

        if not chosen_instance then
            ngx.log(ngx.ERR, "No available backend instance")
            return ngx.exit(503)
        end

        -- 根据映射表将 chosen_instance 转换为实际 IP 地址
        local instance_to_ip = {
            ["api-server1:8080"] = { host = "172.26.0.4", port = 8080 },
            ["api-server2:8080"] = { host = "172.26.0.5", port = 8080 },
        }
        local mapping = instance_to_ip[chosen_instance]
        if not mapping then
            ngx.log(ngx.ERR, "No mapping for chosen instance: ", chosen_instance)
            return ngx.exit(500)
        end

        ngx.log(ngx.INFO, "About to set peer for ", mapping.host, ":", mapping.port)
        local ok, err = balancer.set_current_peer(mapping.host, mapping.port)
        if not ok then
            ngx.log(ngx.ERR, "Failed to set backend peer: ", err)
            return ngx.exit(500)
        end
    }
}
# Server block listening on port 80
server {
    listen 80;
    server_name _;

    # Example location to proxy requests
    location / {
        proxy_pass http://factorization_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # Access log with custom format (optional)
        access_log /var/log/nginx/access.log upstreamlog;
    }
}

